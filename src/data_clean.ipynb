{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8eae61f5",
   "metadata": {},
   "source": [
    "# Data preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8363f646",
   "metadata": {},
   "source": [
    "## Summary of data analysis and findings\n",
    "\n",
    "\n",
    "### Data exploration and analysis\n",
    "- 11 columns from raw dataset\n",
    "- 87489 rows (transactions)\n",
    "- No null values\n",
    "- Mix of float (3) and object (8) dtypes\n",
    "- Exists some outliers for parking_fee\n",
    "    - min = 0 (how does this make sense?)\n",
    "    - max = 983 (this is very high compared to 75th percentile that is 39)\n",
    "    - mean = 31\n",
    "    - std = 39 (quite high compared to mean => high data variance)\n",
    "    - Could for example remove outliers and standardize the data for easier training\n",
    "- Latidute and longitude values are not in the correct range\n",
    "    - min lat = -90 (but we observe -180)\n",
    "    - offsetting wont help since the range is above 180, meaning I do not trust its values to be correctly measured\n",
    "- Longitude is however in the correct range [-180, 180]\n",
    "- Latitude and longitude data by itself does not really give much information and would require some kind of embedding model inbetween, that maps the coordinate point (latitude, longitude) to some feature space that includes information about the location and parking behaviour\n",
    "- not an exact 50/50 split between private and corporate transactions, but they are in the same order of magnitude so stratified sampling is not super necessary\n",
    "- There are 4 different currencies used in the dataset, huge majority is in SEK. 2 options which are both viable\n",
    "    - convert all to SEK equivalent\n",
    "    - remove transactions in other currencies\n",
    "- area_type have 7 different values, \"OnStreet\" and \"SurfaceLot\" are the most common, while \"EVC\" and \"CameraParkArea\" are the least common\n",
    "    - Before removing \"EVC\" and \"CameraParkArea\", we should check if there are any patterns (correlation) in the data that we could use to predict the account_type from those samples\n",
    "- area_type would require categorical encoding (or one-hot encoding), before being used as input to the model.\n",
    "- parking_id is unique as it is a primary key and equal to number of rows in the dataset, meaning it is completely useless for the model\n",
    "- There are a total of 300 registered private and corporate parking users (accounts)\n",
    "- There are a total of 1652 unique car ids used for parking transactions. Since this is larger than the number of parking users, some users have multiple cars, which is indicate of a business account (business has a fleet of cars). Could be useful to create a feature of number of used/registered cars per user\n",
    "- Each parkinguser_id has only one account_type. If a person has both a private and a corporate account, then they make transactions using different parkinguser_ids!\n",
    "- The time span of the dataset is very long (7 years). So normalizing with this time span is not a good idea. Some users could have been active for a long time while some could have been active for a short time.\n",
    "- Better to normalize with the time span of each parkinguser_id\n",
    "\n",
    "\n",
    "### Data cleaning\n",
    "- no duplicate rows\n",
    "- remove outliers in parking_fee (99th percentile)\n",
    "- removed 0 parking_fee rows\n",
    "- converted time data into datetime\n",
    "\n",
    "### Feature engineering\n",
    "- currency conversion\n",
    "- parking duration (in hours)\n",
    "- parking weekday/weekend\n",
    "- registered cars per user\n",
    "- parking count per user\n",
    "- parking activity per car (parkings per day equivalent)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0310e592",
   "metadata": {},
   "source": [
    "## Data exploration and analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6ad6d22b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import df_utils\n",
    "import functionals\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7ec5bba2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data into Pandas DataFrame\n",
    "data_path = \"assignment-sample-data.csv\"\n",
    "df = pd.read_csv(data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e2e5c19e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display\n",
    "pd.set_option('display.width', 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1e04a826",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>parking_id</th>\n",
       "      <th>area_type</th>\n",
       "      <th>parking_start_time</th>\n",
       "      <th>parking_end_time</th>\n",
       "      <th>parking_fee</th>\n",
       "      <th>currency</th>\n",
       "      <th>parkinguser_id</th>\n",
       "      <th>car_id</th>\n",
       "      <th>lat</th>\n",
       "      <th>lon</th>\n",
       "      <th>account_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>fake_c28a323810</td>\n",
       "      <td>SurfaceLot</td>\n",
       "      <td>2015-03-06 19:55:41</td>\n",
       "      <td>2015-03-06 20:07:00</td>\n",
       "      <td>8.50</td>\n",
       "      <td>SEK</td>\n",
       "      <td>fake_bf5d9b530e</td>\n",
       "      <td>fake_130ae2aeb1</td>\n",
       "      <td>59.246370</td>\n",
       "      <td>18.077019</td>\n",
       "      <td>corporate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>fake_76c21cf355</td>\n",
       "      <td>SurfaceLot</td>\n",
       "      <td>2015-03-06 18:08:20</td>\n",
       "      <td>2015-03-06 19:46:00</td>\n",
       "      <td>15.67</td>\n",
       "      <td>SEK</td>\n",
       "      <td>fake_bf5d9b530e</td>\n",
       "      <td>fake_130ae2aeb1</td>\n",
       "      <td>59.231789</td>\n",
       "      <td>18.083995</td>\n",
       "      <td>corporate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>fake_995ed971a6</td>\n",
       "      <td>OnStreet</td>\n",
       "      <td>2017-07-21 09:55:42</td>\n",
       "      <td>2017-07-21 14:23:50</td>\n",
       "      <td>67.00</td>\n",
       "      <td>SEK</td>\n",
       "      <td>fake_3ba346a0cd</td>\n",
       "      <td>fake_f7a9d564d9</td>\n",
       "      <td>59.350331</td>\n",
       "      <td>18.096649</td>\n",
       "      <td>corporate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>fake_6b81ea4f35</td>\n",
       "      <td>SurfaceLot</td>\n",
       "      <td>2017-07-24 07:21:12</td>\n",
       "      <td>2017-07-24 07:34:31</td>\n",
       "      <td>4.34</td>\n",
       "      <td>SEK</td>\n",
       "      <td>fake_ea19a50003</td>\n",
       "      <td>fake_fae7e31b34</td>\n",
       "      <td>59.315826</td>\n",
       "      <td>18.098355</td>\n",
       "      <td>corporate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>fake_424b61e0eb</td>\n",
       "      <td>SurfaceLot</td>\n",
       "      <td>2015-03-09 12:05:46</td>\n",
       "      <td>2015-03-09 13:57:54</td>\n",
       "      <td>50.50</td>\n",
       "      <td>SEK</td>\n",
       "      <td>fake_1cc1970582</td>\n",
       "      <td>fake_0755f3c71f</td>\n",
       "      <td>59.320919</td>\n",
       "      <td>18.047513</td>\n",
       "      <td>corporate</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        parking_id   area_type   parking_start_time     parking_end_time  parking_fee currency   parkinguser_id           car_id        lat        lon account_type\n",
       "0  fake_c28a323810  SurfaceLot  2015-03-06 19:55:41  2015-03-06 20:07:00         8.50      SEK  fake_bf5d9b530e  fake_130ae2aeb1  59.246370  18.077019    corporate\n",
       "1  fake_76c21cf355  SurfaceLot  2015-03-06 18:08:20  2015-03-06 19:46:00        15.67      SEK  fake_bf5d9b530e  fake_130ae2aeb1  59.231789  18.083995    corporate\n",
       "2  fake_995ed971a6    OnStreet  2017-07-21 09:55:42  2017-07-21 14:23:50        67.00      SEK  fake_3ba346a0cd  fake_f7a9d564d9  59.350331  18.096649    corporate\n",
       "3  fake_6b81ea4f35  SurfaceLot  2017-07-24 07:21:12  2017-07-24 07:34:31         4.34      SEK  fake_ea19a50003  fake_fae7e31b34  59.315826  18.098355    corporate\n",
       "4  fake_424b61e0eb  SurfaceLot  2015-03-09 12:05:46  2015-03-09 13:57:54        50.50      SEK  fake_1cc1970582  fake_0755f3c71f  59.320919  18.047513    corporate"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Show first entries\n",
    "df.head()\n",
    "#print(df.tail())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e242ec8",
   "metadata": {},
   "source": [
    "- 11 columns (10 features, 1 target)\n",
    "- I suspect that the rows are sorted by account_type since first 50 are corporate and last 50 are private. This means we should shuffle before training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3d008071",
   "metadata": {},
   "outputs": [],
   "source": [
    "shuffle_rows = True\n",
    "if shuffle_rows:\n",
    "    df = df.sample(frac=1).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "36312777",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['parking_id', 'area_type', 'parking_start_time', 'parking_end_time', 'parking_fee', 'currency', 'parkinguser_id', 'car_id', 'lat', 'lon', 'account_type'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "386336cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 87489 entries, 0 to 87488\n",
      "Data columns (total 11 columns):\n",
      " #   Column              Non-Null Count  Dtype  \n",
      "---  ------              --------------  -----  \n",
      " 0   parking_id          87489 non-null  object \n",
      " 1   area_type           87489 non-null  object \n",
      " 2   parking_start_time  87489 non-null  object \n",
      " 3   parking_end_time    87489 non-null  object \n",
      " 4   parking_fee         87489 non-null  float64\n",
      " 5   currency            87489 non-null  object \n",
      " 6   parkinguser_id      87489 non-null  object \n",
      " 7   car_id              87489 non-null  object \n",
      " 8   lat                 87489 non-null  float64\n",
      " 9   lon                 87489 non-null  float64\n",
      " 10  account_type        87489 non-null  object \n",
      "dtypes: float64(3), object(8)\n",
      "memory usage: 7.3+ MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(df.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d8e4ed3",
   "metadata": {},
   "source": [
    "- 11 columns from raw dataset\n",
    "- 87489 rows (transactions)\n",
    "- No null values\n",
    "- Mix of float (3) and object (8) dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8804a880",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        parking_fee           lat           lon\n",
      "count  87489.000000  87489.000000  87489.000000\n",
      "mean      31.786153     58.786174     17.035432\n",
      "std       39.338515      2.925073      2.639340\n",
      "min        0.000000   -180.006219   -180.006783\n",
      "25%        9.000000     59.292461     17.137638\n",
      "50%       18.750000     59.332389     18.000587\n",
      "75%       39.100000     59.360741     18.066440\n",
      "max      983.000000     67.871132     54.009971\n"
     ]
    }
   ],
   "source": [
    "print(df.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16bd53fd",
   "metadata": {},
   "source": [
    "- Exists some outliers for parking_fee\n",
    "    - min = 0 (how does this make sense?)\n",
    "    - max = 983 (this is very high compared to 75th percentile that is 39)\n",
    "    - mean = 31\n",
    "    - std = 39 (quite high compared to mean => high data variance)\n",
    "    - Could for example remove outliers and standardize the data for easier training\n",
    "- Latidute and longitude values are not in the correct range\n",
    "    - min lat = -90 (but we observe -180)\n",
    "    - offsetting wont help since the range is above 180, meaning I do not trust its values to be correctly measured\n",
    "- Longitude is however in the correct range [-180, 180]\n",
    "- Latitude and longitude data by itself does not really give much information and would require some kind of embedding model inbetween, that maps the coordinate point (latitude, longitude) to some feature space that includes information about the location and parking behaviour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "71a82357",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['corporate' 'private']\n",
      "account_type\n",
      "private      57239\n",
      "corporate    30250\n",
      "Name: count, dtype: int64\n",
      "-----\n",
      "['SEK' 'NOK' 'DKK' 'EUR']\n",
      "currency\n",
      "SEK    86918\n",
      "NOK      465\n",
      "DKK       87\n",
      "EUR       19\n",
      "Name: count, dtype: int64\n",
      "-----\n",
      "['OnStreet' 'SurfaceLot' 'AboveGroundGarage' 'Administrative'\n",
      " 'UndergroundGarage' 'EVC' 'CameraParkArea']\n",
      "area_type\n",
      "OnStreet             52747\n",
      "SurfaceLot           26749\n",
      "Administrative        6269\n",
      "UndergroundGarage     1248\n",
      "AboveGroundGarage      459\n",
      "EVC                     14\n",
      "CameraParkArea           3\n",
      "Name: count, dtype: int64\n",
      "-----\n",
      "Number of rows in df: 87489\n",
      "Number of unique parking_ids: 87489\n",
      "Number of unique parkinguser_ids: 300\n",
      "Number of unique car_ids: 1652\n"
     ]
    }
   ],
   "source": [
    "print(df[\"account_type\"].unique())\n",
    "print(df[\"account_type\"].value_counts())\n",
    "print(5*\"-\")\n",
    "print(df[\"currency\"].unique())\n",
    "print(df[\"currency\"].value_counts())\n",
    "print(5*\"-\")\n",
    "print(df[\"area_type\"].unique())\n",
    "print(df[\"area_type\"].value_counts())\n",
    "print(5*\"-\")\n",
    "print(f\"Number of rows in df: {len(df)}\")\n",
    "print(f\"Number of unique parking_ids: {df['parking_id'].nunique()}\")\n",
    "print(f\"Number of unique parkinguser_ids: {df['parkinguser_id'].nunique()}\")\n",
    "print(f\"Number of unique car_ids: {df['car_id'].nunique()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5193874",
   "metadata": {},
   "source": [
    "- not an exact 50/50 split between private and corporate transactions, but they are in the same order of magnitude so stratified sampling is not super necessary\n",
    "- There are 4 different currencies used in the dataset, huge majority is in SEK. 2 options which are both viable\n",
    "    - convert all to SEK equivalent\n",
    "    - remove transactions in other currencies\n",
    "- area_type have 7 different values, \"OnStreet\" and \"SurfaceLot\" are the most common, while \"EVC\" and \"CameraParkArea\" are the least common\n",
    "    - Before removing \"EVC\" and \"CameraParkArea\", we should check if there are any patterns (correlation) in the data that we could use to predict the account_type from those samples\n",
    "- area_type would require categorical encoding (or one-hot encoding), before being used as input to the model.\n",
    "- parking_id is unique as it is a primary key and equal to number of rows in the dataset, meaning it is completely useless for the model\n",
    "- There are a total of 300 registered private and corporate parking users (accounts)\n",
    "- There are a total of 1652 unique car ids used for parking transactions. Since this is larger than the number of parking users, some users have multiple cars, which is indicate of a business account (business has a fleet of cars). Could be useful to create a feature of number of used/registered cars per user"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc48d774",
   "metadata": {},
   "source": [
    "### Check if transactions with \"parkinguser_id\" exits with multiple account types (corporate and private)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3b3561f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "parkinguser_ids = {} # parkinguser_id -> account_type\n",
    "\n",
    "# Loop over all transactions\n",
    "for index, row in df.iterrows(): \n",
    "    user_id = row['parkinguser_id']\n",
    "    account_type = row['account_type']\n",
    "\n",
    "    if user_id not in parkinguser_ids: # If user_id is not in the dictionary, add it\n",
    "        parkinguser_ids[user_id] = account_type\n",
    "    else: # If user_id is already in the dictionary, check if the account_type is the same\n",
    "\n",
    "        if parkinguser_ids[user_id] != account_type:\n",
    "            print(f\"User {user_id} has multiple account types: {parkinguser_ids[user_id]} and {account_type}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02f1c2da",
   "metadata": {},
   "source": [
    "- Each parkinguser_id has only one account_type. If a person has both a private and a corporate account, then they make transactions using different parkinguser_ids!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b846c59",
   "metadata": {},
   "source": [
    "## Check if private accounts use cars that corporate accounts have used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7877e8ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transactions with car_id fake_3c010b1ca5:\n",
      "            parking_id   parkinguser_id           car_id account_type\n",
      "60360  fake_29e57ca780  fake_c28849a708  fake_3c010b1ca5    corporate\n",
      "70266  fake_0885e9aca0  fake_c28849a708  fake_3c010b1ca5    corporate\n",
      "85870  fake_5aea0993d9  fake_c28849a708  fake_3c010b1ca5    corporate\n",
      "\n",
      "Transactions with car_id fake_3c010b1ca5:\n",
      "            parking_id   parkinguser_id           car_id account_type\n",
      "60360  fake_29e57ca780  fake_c28849a708  fake_3c010b1ca5    corporate\n",
      "70266  fake_0885e9aca0  fake_c28849a708  fake_3c010b1ca5    corporate\n",
      "85870  fake_5aea0993d9  fake_c28849a708  fake_3c010b1ca5    corporate\n",
      "\n"
     ]
    }
   ],
   "source": [
    "violations = functionals.corporate_car(df)\n",
    "\n",
    "for index, row in violations.iterrows():\n",
    "    car_id = row['car_id']\n",
    "    parkinguser_id = row['parkinguser_id']\n",
    "    matching_transactions = df[(df['car_id'] == car_id) & (df['parkinguser_id'] != parkinguser_id)]\n",
    "    print(f\"Transactions with car_id {car_id}:\")\n",
    "    print(matching_transactions[['parking_id', 'parkinguser_id', 'car_id', 'account_type']])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29e39330",
   "metadata": {},
   "source": [
    "### Check private accounts that "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9d53e7ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>car_id</th>\n",
       "      <th>user_count</th>\n",
       "      <th>user_ids</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>384</th>\n",
       "      <td>fake_3c010b1ca5</td>\n",
       "      <td>2</td>\n",
       "      <td>[fake_c8f3930a70, fake_c28849a708]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1050</th>\n",
       "      <td>fake_a46999824b</td>\n",
       "      <td>2</td>\n",
       "      <td>[fake_cef59702cd, fake_b34f71b684]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1472</th>\n",
       "      <td>fake_e877be7731</td>\n",
       "      <td>2</td>\n",
       "      <td>[fake_b34f71b684, fake_cef59702cd]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1567</th>\n",
       "      <td>fake_f52eb84892</td>\n",
       "      <td>2</td>\n",
       "      <td>[fake_b34f71b684, fake_cef59702cd]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               car_id  user_count                            user_ids\n",
       "384   fake_3c010b1ca5           2  [fake_c8f3930a70, fake_c28849a708]\n",
       "1050  fake_a46999824b           2  [fake_cef59702cd, fake_b34f71b684]\n",
       "1472  fake_e877be7731           2  [fake_b34f71b684, fake_cef59702cd]\n",
       "1567  fake_f52eb84892           2  [fake_b34f71b684, fake_cef59702cd]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shared_cars = functionals.shared_car(df)\n",
    "len(shared_cars)\n",
    "shared_cars"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "807fad54",
   "metadata": {},
   "source": [
    "### Max datetime range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7ca77366",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Earliest transaction start: 2013-02-08 10:40:58\n",
      "Latest transaction end: 2020-09-30 14:34:35\n",
      "Total time span: 2791 days, 3 hours\n"
     ]
    }
   ],
   "source": [
    "# Data time range\n",
    "df['parking_start_time'] = pd.to_datetime(df[\"parking_start_time\"])\n",
    "df['parking_end_time'] = pd.to_datetime(df[\"parking_end_time\"])\n",
    "\n",
    "# Find the earliest start time and latest end time\n",
    "earliest_start = df['parking_start_time'].min()\n",
    "latest_end = df['parking_end_time'].max()\n",
    "\n",
    "# Calculate the total time span\n",
    "time_span = latest_end - earliest_start\n",
    "\n",
    "print(f\"Earliest transaction start: {earliest_start}\")\n",
    "print(f\"Latest transaction end: {latest_end}\")\n",
    "print(f\"Total time span: {time_span.days} days, {time_span.seconds // 3600} hours\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5683a3e8",
   "metadata": {},
   "source": [
    "- The time span of the dataset is very long (7 years). So normalizing with this time span is not a good idea. Some users could have been active for a long time while some could have been active for a short time.\n",
    "- Better to normalize with the time span of each parkinguser_id"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b9e60f1",
   "metadata": {},
   "source": [
    "## Data cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3e62ebc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of duplicate rows (excluding parking_id): 0\n",
      "No duplicate rows found when excluding parking_id\n",
      "-----\n",
      "Number of rows before filtering: 87489\n",
      "Number of rows after filtering: 81428\n",
      "Number of rows removed: 6061 (6.93%)\n",
      "-----\n"
     ]
    }
   ],
   "source": [
    "## Remove duplicate rows\n",
    "\n",
    "# Create a temporary DataFrame without the parking_id column and check for duplicates\n",
    "temp_df = df.drop(columns=['parking_id'])\n",
    "duplicate_rows = temp_df[temp_df.duplicated(keep=False)]\n",
    "print(f\"Number of duplicate rows (excluding parking_id): {len(duplicate_rows)}\")\n",
    "if not duplicate_rows.empty:\n",
    "    print(\"\\nDuplicate rows (excluding parking_id):\")\n",
    "    display(duplicate_rows.sort_values(by=temp_df.columns.tolist()))\n",
    "else:\n",
    "    print(\"No duplicate rows found when excluding parking_id\")\n",
    "\n",
    "\n",
    "print(5*\"-\")\n",
    "\n",
    "# Remove outliers in some features\n",
    "\n",
    "# Calculate the 99th percentile of parking_fee\n",
    "percentile = 0.99\n",
    "fee_cutoff_value = df['parking_fee'].quantile(percentile)\n",
    "rows_before = len(df)\n",
    "df = df[(df['parking_fee'] > 0) & (df['parking_fee'] <= fee_cutoff_value)]\n",
    "rows_removed = rows_before - len(df)\n",
    "rows_removed_pct = (rows_removed / rows_before) * 100\n",
    "print(f\"Number of rows before filtering: {rows_before}\")\n",
    "print(f\"Number of rows after filtering: {len(df)}\")\n",
    "print(f\"Number of rows removed: {rows_removed} ({rows_removed_pct:.2f}%)\")\n",
    "\n",
    "print(5*\"-\")\n",
    "\n",
    "## Convert date columns to datetime\n",
    "df['parking_start_time'] = pd.to_datetime(df['parking_start_time'])\n",
    "df['parking_end_time'] = pd.to_datetime(df['parking_end_time'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ed74074",
   "metadata": {},
   "source": [
    "- no duplicate rows\n",
    "- remove outliers in parking_fee (99th percentile)\n",
    "- removed 0 parking_fee rows\n",
    "- converted time data into datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4089329",
   "metadata": {},
   "source": [
    "## Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69ac6854",
   "metadata": {},
   "source": [
    "### Currency conversion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d6b4379f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            parking_id   area_type  parking_start_time    parking_end_time  parking_fee currency   parkinguser_id           car_id        lat        lon account_type  parking_fee_sek\n",
      "22897  fake_8b35b07935    OnStreet 2015-07-22 16:22:05 2015-07-23 16:22:05        20.68      EUR  fake_bcd016dbea  fake_ec45f6cb62  44.112857   9.812206      private         229.7548\n",
      "23695  fake_572f64c80c    OnStreet 2015-07-23 16:24:09 2015-07-24 08:40:00         7.34      EUR  fake_bcd016dbea  fake_ec45f6cb62  44.137471   9.649915      private          81.5474\n",
      "24370  fake_2ae74d8bbe    OnStreet 2018-08-11 09:13:33 2018-08-11 15:55:00         5.35      EUR  fake_ade3f3f432  fake_e025bdf7d3  46.534735  12.134786      private          59.4385\n",
      "26999  fake_56f5699a58  SurfaceLot 2019-01-05 16:37:22 2019-01-05 17:30:00         2.00      EUR  fake_ade3f3f432  fake_e996210230  46.463216  12.204619      private          22.2200\n",
      "30833  fake_b6a291edfe    OnStreet 2019-01-02 14:51:02 2019-01-02 18:21:29         3.50      EUR  fake_ade3f3f432  fake_e996210230  46.532441  12.132596      private          38.8850\n"
     ]
    }
   ],
   "source": [
    "df[\"parking_fee_sek\"] = df[[\"currency\", \"parking_fee\"]].apply(df_utils.convert_currency, axis=1)\n",
    "print(df[df[\"currency\"] == \"EUR\"].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ba90453",
   "metadata": {},
   "source": [
    "### Parking duration (in hours)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ce66c5dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"parking_duration\"] = df[[\"parking_start_time\", \"parking_end_time\"]].apply(lambda x: (x[\"parking_end_time\"] - x[\"parking_start_time\"]).total_seconds() / 3600, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "824d5295",
   "metadata": {},
   "source": [
    "### Weekday calculation (weekday = 1, weekend = 0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a17caed2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"weekday\"] = df.apply(df_utils.get_weekday, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "885ed38b",
   "metadata": {},
   "source": [
    "### Unique cars used per account"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "54bc4b35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        parking_id   parkinguser_id           car_id  registered_cars account_type\n",
      "0  fake_e496407dea  fake_ea19a50003  fake_13b1cf2b6f                4    corporate\n",
      "1  fake_bcfc81657d  fake_39e1ea9867  fake_b859c8ff45                6      private\n",
      "2  fake_c0fa7214a5  fake_b4c70dbc62  fake_33b1fa2d81                4      private\n",
      "3  fake_f2054a145c  fake_378f52df90  fake_2f41fcef59                8    corporate\n",
      "4  fake_575baa98f4  fake_be4166eac6  fake_ee275f6388                3      private\n",
      "5  fake_4410592c3b  fake_d317e5c7a5  fake_8839d145c1                6    corporate\n",
      "6  fake_58f6eb7388  fake_0cbece604e  fake_9ba7328998               10    corporate\n",
      "7  fake_843ab08c49  fake_69eb5c2e45  fake_7df9ab8156               11      private\n",
      "8  fake_4d7bb74b8b  fake_bbf150fdee  fake_9e877c941f                5      private\n",
      "9  fake_a00a24437a  fake_90fc35ed54  fake_5349f3182d                5    corporate\n"
     ]
    }
   ],
   "source": [
    "# Count unique cars per user\n",
    "user_car_counts = df.groupby(\"parkinguser_id\")[\"car_id\"].nunique()\n",
    "\n",
    "# Map the counts back to the original dataframe\n",
    "df[\"registered_cars\"] = df[\"parkinguser_id\"].map(user_car_counts)\n",
    "\n",
    "# Display the first few rows to verify\n",
    "print(df[[\"parking_id\",\"parkinguser_id\", \"car_id\", \"registered_cars\", \"account_type\"]].head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bb46f98",
   "metadata": {},
   "source": [
    "### Parking count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "00dde155",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    parkinguser_id  n_parkings account_type\n",
      "0  fake_ea19a50003        1387    corporate\n",
      "1  fake_39e1ea9867         206      private\n",
      "2  fake_b4c70dbc62         722      private\n",
      "3  fake_378f52df90         358    corporate\n",
      "4  fake_be4166eac6         269      private\n",
      "5  fake_d317e5c7a5        1965    corporate\n",
      "6  fake_0cbece604e        2848    corporate\n",
      "7  fake_69eb5c2e45         346      private\n",
      "8  fake_bbf150fdee         262      private\n",
      "9  fake_90fc35ed54         473    corporate\n"
     ]
    }
   ],
   "source": [
    "# Count total parking transactions per user\n",
    "user_parking_counts = df['parkinguser_id'].value_counts()\n",
    "df['n_parkings'] = df['parkinguser_id'].map(user_parking_counts)\n",
    "print(df[['parkinguser_id', 'n_parkings', \"account_type\"]].head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20df3b35",
   "metadata": {},
   "source": [
    "### Parking activity (normalized w.r.t days)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b31f38ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample of user parking activity (parkings per day):\n",
      "    parkinguser_id  n_parkings  parking_activity account_type\n",
      "0  fake_ea19a50003        1387          1.045215    corporate\n",
      "1  fake_39e1ea9867         206          0.169827      private\n",
      "2  fake_b4c70dbc62         722          0.287879      private\n",
      "3  fake_378f52df90         358          0.330258    corporate\n",
      "4  fake_be4166eac6         269          0.181880      private\n",
      "5  fake_d317e5c7a5        1965          1.234296    corporate\n",
      "6  fake_0cbece604e        2848          1.032632    corporate\n",
      "7  fake_69eb5c2e45         346          0.257058      private\n",
      "8  fake_bbf150fdee         262          0.258383      private\n",
      "9  fake_90fc35ed54         473          0.633199    corporate\n",
      "\n",
      "Summary statistics for parking_activity:\n",
      "count    81428.000000\n",
      "mean         0.471321\n",
      "std          0.330562\n",
      "min          0.005571\n",
      "25%          0.195626\n",
      "50%          0.370934\n",
      "75%          0.742671\n",
      "max          1.234296\n",
      "Name: parking_activity, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Normalize parking frequency with respect to days used\n",
    "\n",
    "\n",
    "# Ensure the timestamp columns are in datetime format\n",
    "df[\"parking_start_time\"] = pd.to_datetime(df[\"parking_start_time\"])\n",
    "df[\"parking_end_time\"] = pd.to_datetime(df[\"parking_end_time\"])\n",
    "\n",
    "# Calculate account age in days for each user\n",
    "user_first_last = df.groupby(\"parkinguser_id\").agg(\n",
    "    first_parking=(\"parking_start_time\", \"min\"),\n",
    "    last_parking=(\"parking_end_time\", \"max\")\n",
    ")\n",
    "\n",
    "# Calculate account age in days (add 1 to avoid division by zero for single transactions)\n",
    "user_first_last[\"account_age_days\"] = (user_first_last[\"last_parking\"] - user_first_last[\"first_parking\"]).dt.days + 1\n",
    "\n",
    "# Get total parkings per user (we already have this in \"n_parkings\")\n",
    "# Calculate parking activity (parkings per day)\n",
    "user_first_last[\"parking_activity\"] = df.groupby(\"parkinguser_id\").size() / user_first_last[\"account_age_days\"]\n",
    "\n",
    "# Map the parking_activity back to the original dataframe\n",
    "df = df.merge(\n",
    "    user_first_last[[\"parking_activity\"]],\n",
    "    left_on=\"parkinguser_id\",\n",
    "    right_index=True,\n",
    "    how=\"left\"\n",
    ")\n",
    "\n",
    "# Display the results\n",
    "print(\"Sample of user parking activity (parkings per day):\")\n",
    "print(df[[\"parkinguser_id\", \"n_parkings\", \"parking_activity\", \"account_type\"]].head(10))\n",
    "print(\"\\nSummary statistics for parking_activity:\")\n",
    "print(df[\"parking_activity\"].describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "628841b5",
   "metadata": {},
   "source": [
    "- This feature has pros and cons. If the parking activity is uniform then it will measure average activity pretty well. However, if the activity is not uniform (such as a big break between parkings) then the acitivity will be underestimated.\n",
    "- Parking activity could be a good way to measure activity per day is a better measure compared to total parking transactions since a private user that has used the app for a long time will have more parking transactions than a new business user that has just started using the app."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87ff2e2c",
   "metadata": {},
   "source": [
    "## Final Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3b74c995",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop unwanted columns\n",
    "df = df.drop(columns=['parking_id', \"parking_fee\", 'lat', 'lon'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0c7ac54b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>area_type</th>\n",
       "      <th>parking_start_time</th>\n",
       "      <th>parking_end_time</th>\n",
       "      <th>currency</th>\n",
       "      <th>parkinguser_id</th>\n",
       "      <th>car_id</th>\n",
       "      <th>account_type</th>\n",
       "      <th>parking_fee_sek</th>\n",
       "      <th>parking_duration</th>\n",
       "      <th>weekday</th>\n",
       "      <th>registered_cars</th>\n",
       "      <th>n_parkings</th>\n",
       "      <th>parking_activity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>OnStreet</td>\n",
       "      <td>2019-01-26 09:46:07</td>\n",
       "      <td>2019-01-26 16:30:00</td>\n",
       "      <td>SEK</td>\n",
       "      <td>fake_ea19a50003</td>\n",
       "      <td>fake_13b1cf2b6f</td>\n",
       "      <td>corporate</td>\n",
       "      <td>67.50</td>\n",
       "      <td>6.731389</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1387</td>\n",
       "      <td>1.045215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>OnStreet</td>\n",
       "      <td>2020-05-05 08:15:24</td>\n",
       "      <td>2020-05-05 11:58:00</td>\n",
       "      <td>SEK</td>\n",
       "      <td>fake_39e1ea9867</td>\n",
       "      <td>fake_b859c8ff45</td>\n",
       "      <td>private</td>\n",
       "      <td>93.50</td>\n",
       "      <td>3.710000</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>206</td>\n",
       "      <td>0.169827</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SurfaceLot</td>\n",
       "      <td>2017-09-19 06:28:16</td>\n",
       "      <td>2017-09-19 18:38:00</td>\n",
       "      <td>SEK</td>\n",
       "      <td>fake_b4c70dbc62</td>\n",
       "      <td>fake_33b1fa2d81</td>\n",
       "      <td>private</td>\n",
       "      <td>40.00</td>\n",
       "      <td>12.162222</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>722</td>\n",
       "      <td>0.287879</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>OnStreet</td>\n",
       "      <td>2020-03-19 05:27:51</td>\n",
       "      <td>2020-03-19 08:25:00</td>\n",
       "      <td>SEK</td>\n",
       "      <td>fake_378f52df90</td>\n",
       "      <td>fake_2f41fcef59</td>\n",
       "      <td>corporate</td>\n",
       "      <td>28.75</td>\n",
       "      <td>2.952500</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>358</td>\n",
       "      <td>0.330258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>OnStreet</td>\n",
       "      <td>2017-09-05 15:33:50</td>\n",
       "      <td>2017-09-05 16:30:00</td>\n",
       "      <td>SEK</td>\n",
       "      <td>fake_be4166eac6</td>\n",
       "      <td>fake_ee275f6388</td>\n",
       "      <td>private</td>\n",
       "      <td>13.30</td>\n",
       "      <td>0.936111</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>269</td>\n",
       "      <td>0.181880</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    area_type  parking_start_time    parking_end_time currency   parkinguser_id           car_id account_type  parking_fee_sek  parking_duration  weekday  registered_cars  n_parkings  parking_activity\n",
       "0    OnStreet 2019-01-26 09:46:07 2019-01-26 16:30:00      SEK  fake_ea19a50003  fake_13b1cf2b6f    corporate            67.50          6.731389        0                4        1387          1.045215\n",
       "1    OnStreet 2020-05-05 08:15:24 2020-05-05 11:58:00      SEK  fake_39e1ea9867  fake_b859c8ff45      private            93.50          3.710000        1                6         206          0.169827\n",
       "2  SurfaceLot 2017-09-19 06:28:16 2017-09-19 18:38:00      SEK  fake_b4c70dbc62  fake_33b1fa2d81      private            40.00         12.162222        1                4         722          0.287879\n",
       "3    OnStreet 2020-03-19 05:27:51 2020-03-19 08:25:00      SEK  fake_378f52df90  fake_2f41fcef59    corporate            28.75          2.952500        1                8         358          0.330258\n",
       "4    OnStreet 2017-09-05 15:33:50 2017-09-05 16:30:00      SEK  fake_be4166eac6  fake_ee275f6388      private            13.30          0.936111        1                3         269          0.181880"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0024239d",
   "metadata": {},
   "source": [
    "## Save processed data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d82b6632",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_df = False\n",
    "# Save cleaned dataframe\n",
    "if save_df:\n",
    "    clean_path = data_path[:-4] + '-cleaned.csv'\n",
    "    df.to_csv(clean_path, index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
